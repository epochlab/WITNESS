{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BINARY CLASSIFICATION (ELA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, warnings\n",
    "sys.path.append('..')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os, random\n",
    "from glob import glob \n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from arch import utils, ela, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = utils.device_mapper()\n",
    "print(f\"Device: {str(DEVICE).upper()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET = \"/mnt/artemis/library/datasets/image-forgery\"\n",
    "IF_DATASET = \"/mnt/artemis/library/datasets/image-forgery\"\n",
    "CASIA_DATASET = \"/mnt/artemis/library/datasets/casia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_files = [file for d in [IF_DATASET, CASIA_DATASET] for file in glob(os.path.join(d, '**', '*'))]\n",
    "print(f\"Total count: {len(total_files)}\")\n",
    "\n",
    "types = set()\n",
    "for file in total_files: types.add(file.split('.')[-1])\n",
    "print(f\"Types: {types}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Au = (\n",
    "    glob(IF_DATASET + \"/Original/*.jpg\") + \n",
    "    glob(IF_DATASET + \"/Original/*.JPG\") + \n",
    "    glob(IF_DATASET + \"/Original/*.tif\") + \n",
    "    glob(CASIA_DATASET + \"/Au/Au*.jpg\")\n",
    ")\n",
    "Tp = (\n",
    "    glob(IF_DATASET + \"/Forged/*.jpg\") + \n",
    "    glob(IF_DATASET + \"/Forged/*.png\") + \n",
    "    glob(IF_DATASET + \"/Forged/*.tif\") + \n",
    "    glob(CASIA_DATASET + \"/Tp/Tp*.jpg\") + \n",
    "    glob(CASIA_DATASET + \"/Tp/Tp*.tif\")\n",
    ")\n",
    "\n",
    "print(f\"Au files: {len(Au)}\")\n",
    "print(f\"Tp files: {len(Tp)}\")\n",
    "\n",
    "Ds = Au + Tp\n",
    "print(f\"Ds files: {len(Ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 5\n",
    "c = 25\n",
    "\n",
    "sampled_paths = random.sample(Ds, r*c)\n",
    "\n",
    "sample = [Image.open(path).resize((128,128)) for path in sampled_paths[:r*c]]\n",
    "utils.contact_layer(sample, r, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, p, shuffle=True):\n",
    "    if shuffle: random.shuffle(Ds)\n",
    "    bound = int((len(x)/100) * p)\n",
    "    return x[:bound], x[bound:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform, filter=None):\n",
    "        super().__init__()\n",
    "        self.paths = image_paths\n",
    "        self.len = len(self.paths)\n",
    "        self.filter = filter\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): return self.len\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        path = self.paths[idx]\n",
    "        x = Image.open(path).convert('RGB')\n",
    "        if random.random() > 0.5: x = x.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        \n",
    "        if self.filter == 'ela':\n",
    "            x = ela.compute(x, 90)\n",
    "            x = self.transform(utils.array2image(x))\n",
    "        else:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        y = 0 if 'Original' in path or 'Au/Au' in path else 1\n",
    "\n",
    "        return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(x, mean=(0.5,), std=(0.5,)):\n",
    "    mean = torch.tensor(mean).view(-1, 1, 1)\n",
    "    std = torch.tensor(std).view(-1, 1, 1)\n",
    "    return x * std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_data(Ds, 95)\n",
    "\n",
    "Au_count = sum('Original' in path or 'Au' in path for path in train)\n",
    "Tp_count = sum('Forged' in path or 'Tp' in path for path in train)\n",
    "\n",
    "print(f\"Original: {Au_count} | Forged: {Tp_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CustomDataset(train, transform, filter='ela')\n",
    "train_dl = DataLoader(train_ds, batch_size=128)\n",
    "print(f\"(Train) Images: {len(train_ds)} | Batches: {len(train_dl)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dl))\n",
    "print(f\"Image batch shape: {x.shape}\")\n",
    "\n",
    "r, c = 2, 10\n",
    "labels = [f\"Real [{y[i].item()}]\" if y[i].item() == 0 else f\"Edited [{y[i].item()}]\" for i in range(r*c)]\n",
    "data = [utils.array2image(denormalize(x[i]).permute(1, 2, 0).numpy()) for i in range(r*c)]\n",
    "\n",
    "utils.contact_layer(data, r, c, labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net.CNN()\n",
    "model.to(DEVICE)\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(\"Nparams:\", sum(p.nelement() for p in parameters))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.001)\n",
    "\n",
    "epochs = 5\n",
    "lossi, accui = [], []\n",
    "for e in range(epochs):\n",
    "    with tqdm(train_dl, unit='batch') as tepoch:\n",
    "        for xb, yb in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {e+1}\")\n",
    "\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            logits = model(xb)\n",
    "            loss = F.cross_entropy(logits, yb)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            accuracy = ((logits.argmax(dim=1) == yb).float().mean())\n",
    "            \n",
    "            lossi.append(loss.item())\n",
    "            accui.append(accuracy.item())\n",
    "            tepoch.set_postfix(loss=loss.item(), accuracy=accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "model_path = f\"bce_{datetime.now().strftime('%Y%m%d%H%M%S')}.pth\"\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 5))\n",
    "plt.plot(lossi, label='loss', lw=0.5)\n",
    "plt.plot(accui, label='accuracy', lw=0.5)\n",
    "plt.xlim([0, len(lossi)])\n",
    "plt.grid(alpha=0.25)\n",
    "plt.legend(), plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TEST / INFER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net.CNN()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(DEVICE)\n",
    "print(model.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = CustomDataset(test, transform, filter='ela')\n",
    "test_dl = DataLoader(test_ds, batch_size=128)\n",
    "print(f\"(Test) Images: {len(test_ds)} | Batches: {len(test_dl)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    with tqdm(test_dl, unit='batch') as tepoch:\n",
    "        loss, accuracy = 0, 0\n",
    "        for xt, yt in tepoch:\n",
    "            tepoch.set_description(f\"Testing..\")\n",
    "            xt, yt = xt.to(DEVICE), yt.to(DEVICE)\n",
    "            logits = model(xt)\n",
    "\n",
    "            loss += F.cross_entropy(logits, yt)\n",
    "            accuracy += (logits.argmax(dim=1) == yt).float().mean()\n",
    "\n",
    "        loss /= len(test_dl)\n",
    "        accuracy /= len(test_dl)\n",
    "\n",
    "print(f\"Test loss: {loss:.4f}, Test accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = random.sample(test, 10)\n",
    "sample_ds = CustomDataset(sample, transform, filter='ela')\n",
    "sample_dl = DataLoader(sample_ds, batch_size=len(sample_ds))\n",
    "\n",
    "xt, yt = next(iter(sample_dl))\n",
    "xt, yt = xt.to(DEVICE), yt.to(DEVICE)\n",
    "logits = model(xt)\n",
    "preds = F.softmax(logits, dim=1)[:, 1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(2, len(sample_ds), figsize=(len(sample_ds) * 5, 12))\n",
    "for idx, x in enumerate(xt):\n",
    "    pred = preds[idx]\n",
    "    label = \"Forged\" if pred > 0.5 else \"Original\"\n",
    "    axs[0, idx].imshow(Image.open(sample[idx]).resize((224, 224)))\n",
    "    title_color = \"red\" if round(pred, 0) != yt[idx] else \"black\"\n",
    "    axs[0, idx].set_title(f\"{yt[idx].item()} | {pred:.5f} | {label}\", color=title_color)\n",
    "    axs[0, idx].axis(False)\n",
    "    x = denormalize(x.cpu())\n",
    "    axs[1, idx].imshow(x.permute(1, 2, 0).numpy())\n",
    "    axs[1, idx].axis(False)\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
