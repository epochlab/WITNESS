{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LATENT DIFFUSION\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from arch import diffusion, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = utils.device_mapper()\n",
    "print(f\"Device: {str(DEVICE).upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = diffusion.LatentDiffusion(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### TEXT2IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class HyperConfig:\n",
    "    prompt = \"a photograph of a barn on fire, cinematic, film grain, analog, 70mm, technicolor, 4K, IMAX\"\n",
    "    negative_prompt = \"black and white\"\n",
    "    w, h = 1280//2, 720//2\n",
    "    infer_steps = 50\n",
    "    cfg_scale = 7.0\n",
    "    batch_size = 1\n",
    "\n",
    "config = HyperConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in tqdm(range(9)):\n",
    "    latents = pipe.generate(config, random.randint(0, 1e6), 'txt2img')\n",
    "    img = pipe.decode(latents)\n",
    "    images.append(img.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.contact_layer(images, 3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ENCODING & DECODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_image = Image.open('data/macaw.jpg').resize((512, 512))\n",
    "input_image = utils.load_image('data/macaw.jpg')\n",
    "utils.array2image(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode to the latent space\n",
    "encoded = pipe.encode(input_image)\n",
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four channels of latent representation\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "for c in range(4):\n",
    "    axs[c].imshow(encoded[0][c].cpu(), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode to image\n",
    "decoded = pipe.decode(encoded)\n",
    "utils.array2image(decoded.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### IMG2IMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class HyperConfig:\n",
    "    prompt = \"A colorful dancer, nat geo photo\"\n",
    "    negative_prompt = \"\"\n",
    "    w, h = 512, 512\n",
    "    infer_steps = 50\n",
    "    sampling_step = 10\n",
    "    cfg_scale = 8.0\n",
    "    batch_size = 1\n",
    "\n",
    "config = HyperConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.scheduler.set_timesteps(config.infer_steps)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(pipe.scheduler.sigmas)\n",
    "plt.title('Noise Schedule'), plt.xlabel('Sampling Step'), plt.ylabel('Sigma')\n",
    "plt.xlim([0, len(pipe.scheduler.timesteps)])\n",
    "plt.axvline(x=config.sampling_step, color='red', lw='0.1')\n",
    "plt.grid(alpha=0.25), plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn_like(encoded, dtype=torch.float16)\n",
    "encoded_and_noised = pipe.scheduler.add_noise(encoded, noise, timesteps=torch.tensor([pipe.scheduler.timesteps[config.sampling_step]]))\n",
    "\n",
    "img = pipe.decode(encoded_and_noised)\n",
    "utils.array2image(img.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = pipe.generate(config, 12, 'img2img', encoded)\n",
    "img = pipe.decode(latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.array2image(img.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
