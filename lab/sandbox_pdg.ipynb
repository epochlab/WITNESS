{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, warnings\n",
    "sys.path.append('..')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "import torch\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "\n",
    "from arch import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = utils.device_mapper()\n",
    "print(f\"Device: {str(DEVICE).upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = StableDiffusionImg2ImgPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", variant='fp16', torch_dtype=torch.float16)\n",
    "pipeline = pipeline.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/puppy.png')\n",
    "init_image = utils.load_image(PATH)\n",
    "init_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(img: Image.Image) -> torch.Tensor:\n",
    "    # Resize to factor of 32\n",
    "    w, h = map(lambda x: x - x % 32, img.size)\n",
    "    img = img.resize((w, h), resample=Image.LANCZOS)\n",
    "\n",
    "    img = utils.image2array(img, dtype=np.float16)\n",
    "    img = img * 2.0 - 1.0\n",
    "    img = img[None].transpose(0, 3, 1, 2)\n",
    "    return torch.from_numpy(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(x, model, eps=0.1, step_size=0.015, iters=40):\n",
    "    x_adv = x.clone().detach() + (torch.rand_like(x) * 2 * eps - eps)\n",
    "\n",
    "    for i in (t := trange(iters)):\n",
    "        actual_step_size = step_size * (1 - i / iters / 100)\n",
    "\n",
    "        x_adv.requires_grad = True\n",
    "\n",
    "        loss = model(x_adv).latent_dist.mean.norm()\n",
    "        grad = torch.autograd.grad(loss, [x_adv])[0]\n",
    "        x_adv = x_adv.detach() - grad.sign() * actual_step_size\n",
    "\n",
    "        x_adv = torch.clamp(x_adv, x-eps, x+eps)\n",
    "        x_adv = torch.clamp(x_adv, -1, 1)\n",
    "\n",
    "        t.set_description(f\"[Running attack]: Loss {loss.item():.2f} | Actual Step: {actual_step_size:.4f}\")\n",
    "\n",
    "    return x_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps | Higher = Less imperceptible (0.06)\n",
    "# step | Set smaller than eps (0.02)\n",
    "# iters | Higher = Stronger (1000)\n",
    "\n",
    "x = transform(init_image).to(DEVICE)\n",
    "adv_x = pgd_attack(x, model=pipeline.vae.encode, eps=0.06, step_size=0.02, iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_image = (adv_x / 2 + 0.5).clamp(0, 1)\n",
    "adv_image = adv_image.cpu().numpy().transpose(0, 2, 3, 1)[0]\n",
    "adv_image = utils.array2image(adv_image)\n",
    "adv_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class HyperConfig:\n",
    "    prompt = \"a photograph of a dog under heavy rain on muddy ground\"\n",
    "    strength = 0.5\n",
    "    cfg_scale = 7.0\n",
    "    infer_steps = 50\n",
    "\n",
    "config = HyperConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_nat = pipeline(prompt=config.prompt, \n",
    "                        image=init_image, \n",
    "                        strength=config.strength, \n",
    "                        guidance_scale=config.cfg_scale, \n",
    "                        num_inference_steps=config.infer_steps).images[0]\n",
    "\n",
    "image_adv = pipeline(prompt=config.prompt, \n",
    "                        image=adv_image, \n",
    "                        strength=config.strength, \n",
    "                        guidance_scale=config.cfg_scale, \n",
    "                        num_inference_steps=config.infer_steps).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(20,6))\n",
    "\n",
    "ax[0].imshow(init_image)\n",
    "ax[1].imshow(adv_image)\n",
    "ax[2].imshow(image_nat)\n",
    "ax[3].imshow(image_adv)\n",
    "\n",
    "ax[0].set_title('Source Image', fontsize=12)\n",
    "ax[1].set_title('Adv Image', fontsize=12)\n",
    "ax[2].set_title('Gen. Image Nat.', fontsize=12)\n",
    "ax[3].set_title('Gen. Image Adv.', fontsize=12)\n",
    "\n",
    "for i in range(4):\n",
    "    ax[i].grid(False), ax[i].axis('off')\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
